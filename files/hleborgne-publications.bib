@string{PAMI = "IEEE T. Pattern Analysis and Machine Intelligence"}
@string{IJCV = "International Journal of Computer Vision"}
@string{CVIU = "International Journal of Computer Vision and Image Understanding"}

@string{CVPR = "Computer Vision and Pattern Recognition (CVPR)"}
@string{ECCV = "European Conference on Computer Vision (ECCV)"}
@string{ICCV = "International Conference on Computer Vision (ICCV)"}

@string{ACCV = "Asian Conference on Computer Vision (ACCV)"}
@string{BMVC = "British Machine Vision Conference (BMVC)"}
@string{ICIP = "International Conference on Image Processing"}
@string{ICPR = "International Conference on Pattern Recognition (ICPR)"}

@string{ICMR = "International Conference on Multimedia Retrieval (ICMR)"}
@string{ACMMM = "International Conference on Multimedia"}

@string{NIPS = "Advances in Neural Information Processing Systems (NeurIPS)"}
@string{ICLR = "International Conference on Learning Representations (ICLR)"}
@string{ICML = "International Conference on Machine Learning (ICML)"}

@string{SIGIR = "SIGIR Conference on Research and Development in Information Retrieval (SIGIR)"}
@string{ECIR = "European Conference on Information Retrieval (ECIR)"}
@string{ECMLKDD= "Joint European Conference on Machine Learning and Knowledge Discovery in Databases"}

@string{arXiv  = "arXiv"}

@unpublished{grimal2023tiam,
      title={TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation}, 
      author={Paul Grimal and Hervé Le Borgne and Olivier Ferret and Julien Tourille},
      year={2023},
      journal={arXiv 2307.05134},
      note=[Preprint.}
      url = "https://arxiv.org/abs/2307.05134",
      url_PDF = "https://arxiv.org/pdf/2307.05134.pdf",
      abstract = "The progress in the generation of synthetic images has made it crucial to assess their quality. While several metrics have been proposed to assess the rendering of images, it is crucial for Text-to-Image (T2I) models, which generate images based on a prompt, to consider additional aspects such as to which extent the generated image matches the important content of the prompt. Moreover, although the generated images usually result from a random starting point, the influence of this one is generally not considered. In this article, we propose a new metric based on prompt templates to study the alignment between the content specified in the prompt and the corresponding generated images. It allows us to better characterize the alignment in terms of the type of the specified objects, their number, and their color. We conducted a study on several recent T2I models about various aspects. An additional interesting result we obtained with our approach is that image quality can vary drastically depending on the latent noise used as a seed for the images. We also quantify the influence of the number of concepts in the prompt, their order as well as their (color) attributes. Finally, our method allows us to identify some latent seeds that produce better images than others, opening novel directions of research on this understudied topic."
}

@inproceedings{karaliolios2023gpl,
  author          = {Nikolaos Karaliolios and Florian Chabot and Camille Dupont and Hervé Le Borgne and Romaric Audigier and Quoc-Cuong Pham},
  booktitle       = ICIP,
  title           = {Generalized pseudo-labeling in consistency regularization for semi-supervised learning},
  year            = {2023},
  keywords = {conf-int}
}


@article{doubinsky2022prl,
  author     = {Perla Doubinsky and
               Nicolas Audebert and
               Michel Crucianu and
               Herv{\'{e}} Le Borgne},
  title      = {Multi-Attribute Balanced Sampling for Disentangled {GAN} Controls},
  journal    = {Pattern Recognition Letters},
  volume     = {162},
  pages      = {56-62},
  year       = {2022},
  doi        = {https://doi.org/10.1016/j.patrec.2022.08.012},
  keywords   = {journal-int}
}

